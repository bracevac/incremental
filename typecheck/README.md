# Getting Started

This artifact requires a working installation of the Java Development Kit (JDK) >= 6.
We recommend a Unix-like environment with a standard Bourne shell (`/bin/sh`),
as we included shell scripts which facilitate running our benchmarks specific
to this platform.

For reference, we ran the performance evaluation on a machine with Oracle JDK 7 (64bit), 
Mac OS X 10.10, a 2.8 Ghz Core i7 processor and 8 GB RAM.

In addition, a working internet connection plus the Scala build tool `sbt` (http://www.scala-sbt.org/) 
are required to fetch software dependencies, perform compilation and run the benchmarks. 
We bundled a version of `sbt` with this artifact,
which we recommend choosing over a local installation. Our bundled version sets
the JVM options such that they are in accordance to our evaluation, i.e., `-Xms2048M -Xmx2048M`.

## Artifact Contents

We list the folders and files which are most relevant for artifact evaluation:

* `./incremental.sh`: Invokes the incremental performance test suite (sec. 6 in the paper). 
* `./nonincremental.sh`: Invokes the nonincremental performance test suite (sec. 6 in the paper)
* `./src/main/scala/`: The root directory of the artifact's Scala source code.
  * `benchmark/`: Sources of the performance evaluation.
    * `pcf/Nonincremental.scala`: Source of the nonincremental performance test suite.
    * `pcf/Incremental.scala`: Source of the incremental performance test suite.
  * `incremental/`: Source code of the incremental type checkers.
* `./benchmark_paper/`: Contains the raw data files of our published performance results for reference. See below for an explanation of the data format. 
Note that we manually created Excel spreadsheet files (`*.xlsx`) from the raw data, where we added a `speed` column to compute the average time per node spent.



# Step by Step Guide for Performance Evaluation

1. From a terminal, `cd` into the folder where you unzipped the artifact.

2. For the *nonincremental* performance test suite (figure 8, top half), enter
`./nonincremental.sh 16`. For the *incremental* performance test suite (figure 8, bottom half),
enter `./incremental.sh 16`. 
Each test runs the type checkers DU, BU1, ..., BU4 against synthetic expression trees of height k = 2, 4, 6, 8, ... 16,
which are generated using ScalaMeter's DSL (https://scalameter.github.io). For details refer to the source files we listed above. 
The terminal output you will see is generated by ScalaMeter and is only of minor importance,
as it writes measurement results out to files.
It can take up to an hour or more per test suite, as ScalaMeter performs GC warmups and runs each test
multiple times to collect statistics.
You are welcome to substitute the height parameter 16 for some other positive integer in the invocation. 
For higher numbers you may want to change the JVM heap size by editing the `./sbt` script file in the folder.

3. After you have run the tests, there should be the following files/folders in the current directory:
  * `./benchmark/`
    * `incremental/`: Delimiter Separated Values (DSV) files of incremental performance results. See next section for details.
    * `nonincremental/`: DSV files for nonincremental performance results.
  * `./tmp/report/index.html`: A graphical plot of ScalaMeter's performance results, which can be viewed in any modern web browser. This is the way we obtained figure 9 for our paper. 
Note that this shows only the results of either `incremental` or `nonincremental`, but not both.
   
# Data Format

Our test suites employ ScalaMeter's DSV, HTML and RegressionReporter from version 0.6. For details, 
see [here](https://scalameter.github.io/home/gettingstarted/0.5/reporters/index.html).

The `*.dsv` files in the `benchmark` subfolders are of primary interest for reproduction of our results.
We also keep persisted history data of past runs for regression testing (`*.dat` files).

Each DSV file is named after the following pattern:

     [tree shape].[type checker name].test-##.dsv

For example, the raw performance values for the first row and first column in figure 8(b) are located in 
`./benchmark/nonincremental/Abs\{x,Tree\{Add,\[x1..xn\]\}\}.DU.Test-8.dsv`.

A row in a DSV corresponds to a test run for the given tree shape, type checker and a specific 
height k = 2, 4, 6 ... up to the maximum height specified by the user. The columns contain the following information:

1. Time stamp of test execution.
2. Height parameter k.
3. Average wall-clock time measured.
4. Test success indicator.
5. Lower bound of confidence interval.
6. Upper bound of confidence interval.
7. Unit of measure (milliseconds).
8. The list of all measured well-clock time samples for this particular configuration.

Note that the delimiter in the DSV files is a single whitespace.

We computed the nodes per milliseconds and speedups shown in figure 8 from the wall-clock times 
in a spreadsheet after importing the DSV files.






